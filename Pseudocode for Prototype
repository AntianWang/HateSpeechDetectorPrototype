# interfaces: assume existed
# 1. kernel SVM, denote kSVM
#    Input: [(x_i, c_i, y_i)]
#    Output: w, b
# 2. Autoencoder, denote AE
#    Input: [x_i]
#    Output: PC[n]
# 3. Other baseline models (Assume 4 of them, as in README), denote M[0], M[1], M[2], M[3]
#    Input: [(x_i, c_i, y_i)]
#    Output: w, b (such that predictions are made by w \cdot x + b closer to 1 or 0)
# 4. Adaboost
#    Input: testing functions for all models
#    Output: w (a vector of weights of all models in order above)

def kSVM(data):
    pass
    
def AE(data):
    pass
   
# this function returns (cluster function, information gain of the clustering based on the given PC dimension)
def Cluster(data, PC): 
    pass

def PM(data):
    pass
M = [PM, PM, PM, PM]

def kernel(x, x'):
    pass
    
####################### train ####################### 
import csv
import numpy as np

with open('dataset.csv', newline='') as f:
    reader = csv.reader(f)
    data = [tuple(row) for row in reader]
    
# kernel SVM
SVM_alpha, SVM_b = kSVM(data)
def SVM_fn((x, c)):
    ctx = np.array([c for (_, c, _) in data])
    ctx_dot = np.multiply(ctx, c)
    new_w = np.multiply(ctx.dot, w)
    dot = kernel(x, new_w)
    return 1 if dot + b > 0 else 0
    
# Autoencoder
transdata = [x_i for (x_i, _, _) in data]
PC = AE(transdata)
score = []
for i in range(len(PC)):
    # now we use data instead of transdata, since we need y values for clustering
    score.append(Cluster(data, PC[i])[1])
max_score = 0
opt_PC = PC[0]
for i in range(len(PC)):
    if score[i] > max_score:
        max_score = score[i]
        opt_PC = PC[i]
opt_cl = Cluster(transdata, opt_PC)[0]
# note this opt_cl is a function that takes in x and outputs predicted y (cluster 0 or 1)
def AE_fn((x, c)):
    return opt_cl(x)

# Other models
W, b = []
for i in range(4):
    W[i], b[i] = M[i](data)
def M_fn_wrapper(i):
    def M_fn((x, c)):
      return 1 if np.dot(x, W[i]) + b > .5 else 0
    return M_fn
M_fn = [M_fn_wrapper(i) for i in range(4)]

# Ensemble
weight_of_models = Adaboost(SVM_fn, AE_fn, M_fn[0], M_fn[1], M_fn[2], M_fn[3])


####################### test ####################### 
x = input()
c = input()
res = [SVM_fn((x, c)), AE_fn((x, c)), M_fn[0]((x, c)), M_fn[1]((x, c)), M_fn[2]((x, c)), M_fn[3]((x, c))]
weighted_res = np.dot(res, weight_of_models)
return 1 if weighted_res > .5 else 0

